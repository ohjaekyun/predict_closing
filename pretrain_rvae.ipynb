{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import tensor as Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from models.rnn import CMV_LSTM, MV_LSTM\n",
    "from models.vae import ConditionalVAE, VanillaVAEEncoder, VanillaVAEDecoder\n",
    "from models.rvae import UnitRVAE, RVAE\n",
    "from utils.loss import VAE_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "batch_size = 4\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_datas(seq_length, data, shuffle=True):\n",
    "    total_num = len(data)\n",
    "    list_x_datas = []\n",
    "    list_y_datas = []\n",
    "    for i in range(seq_length, total_num):\n",
    "        list_y_datas.append(data[i].reshape([1, *data[i].shape]))\n",
    "        list_x_datas.append(data[i - seq_length:i].copy().reshape([1, *data[i - seq_length:i].shape]))\n",
    "    \n",
    "    if shuffle:\n",
    "        suffled_idices = list(range(len(list_x_datas)))\n",
    "        random.shuffle(suffled_idices)\n",
    "        list_x_datas1 = []\n",
    "        list_y_datas1 = []\n",
    "        for i in suffled_idices:\n",
    "            list_x_datas1.append(list_x_datas[i])\n",
    "            list_y_datas1.append(list_y_datas[i])\n",
    "        return np.vstack(list_x_datas1), np.vstack(list_y_datas1)\n",
    "    return np.vstack(list_x_datas), np.vstack(list_y_datas)\n",
    "\n",
    "\n",
    "class timeseries(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_econs = pd.read_csv('data/total_economy_data.csv', index_col=0)\n",
    "df_econs1 = df_econs.drop(columns=['year', 'month'])\n",
    "df_econs1 = df_econs1.dropna(axis=1)\n",
    "arr_econs = df_econs1.to_numpy()\n",
    "arr_econs = arr_econs / 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iteration :  tensor(30.8104, grad_fn=<AddBackward0>)\n",
      "2 th iteration :  tensor(32.5572, grad_fn=<AddBackward0>)\n",
      "4 th iteration :  tensor(38.4819, grad_fn=<AddBackward0>)\n",
      "6 th iteration :  tensor(43.9157, grad_fn=<AddBackward0>)\n",
      "8 th iteration :  tensor(23.6326, grad_fn=<AddBackward0>)\n",
      "10 th iteration :  tensor(29.4062, grad_fn=<AddBackward0>)\n",
      "12 th iteration :  tensor(30.8977, grad_fn=<AddBackward0>)\n",
      "14 th iteration :  tensor(14.0472, grad_fn=<AddBackward0>)\n",
      "16 th iteration :  tensor(18.6920, grad_fn=<AddBackward0>)\n",
      "18 th iteration :  tensor(17.5703, grad_fn=<AddBackward0>)\n",
      "20 th iteration :  tensor(26.2875, grad_fn=<AddBackward0>)\n",
      "22 th iteration :  tensor(18.1912, grad_fn=<AddBackward0>)\n",
      "24 th iteration :  tensor(15.2267, grad_fn=<AddBackward0>)\n",
      "26 th iteration :  tensor(15.6488, grad_fn=<AddBackward0>)\n",
      "28 th iteration :  tensor(20.5717, grad_fn=<AddBackward0>)\n",
      "30 th iteration :  tensor(28.4618, grad_fn=<AddBackward0>)\n",
      "32 th iteration :  tensor(29.1979, grad_fn=<AddBackward0>)\n",
      "34 th iteration :  tensor(15.1386, grad_fn=<AddBackward0>)\n",
      "36 th iteration :  tensor(30.8973, grad_fn=<AddBackward0>)\n",
      "38 th iteration :  tensor(16.6566, grad_fn=<AddBackward0>)\n",
      "40 th iteration :  tensor(29.3997, grad_fn=<AddBackward0>)\n",
      "42 th iteration :  tensor(27.9182, grad_fn=<AddBackward0>)\n",
      "44 th iteration :  tensor(32.9914, grad_fn=<AddBackward0>)\n",
      "46 th iteration :  tensor(12.6901, grad_fn=<AddBackward0>)\n",
      "48 th iteration :  tensor(21.8516, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Pretrain\n",
    "\n",
    "train_data = arr_econs\n",
    "urvae = UnitRVAE(arr_econs.shape[-1], seq_len, 28)\n",
    "\n",
    "x_train, y_train = get_total_datas(seq_len, train_data, shuffle=True)\n",
    "ts_dataset = timeseries(x_train, y_train)\n",
    "\n",
    "\n",
    "model = urvae.to(device)\n",
    "urvae.rnn.init_hidden(batch_size)\n",
    "criterion = VAE_Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "epochs = 50\n",
    "\n",
    "for i in range(epochs):\n",
    "    ts_train_loader = DataLoader(ts_dataset, shuffle=True, batch_size=batch_size)\n",
    "    model.train()\n",
    "    for j, data in enumerate(ts_train_loader):\n",
    "        if data[0].shape[0] != batch_size:\n",
    "            break\n",
    "        curr_data = data[0].clone().detach(), data[1].clone().detach()\n",
    "        output = model(curr_data[0])\n",
    "        loss = criterion(output[2], output[3], output[0], curr_data[1])\n",
    "        #make_dot(loss, params=dict(model.named_parameters())).render(f\"graph\", format=\"png\")\n",
    "        #result = model.loss_function(curr_data[1].clone(), *output, **{'M_N': 1})\n",
    "        #loss = result['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    if i % 2 == 0:\n",
    "        print(i, 'th iteration : ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_total_datas(seq_len, train_data, shuffle=True)\n",
    "ts_dataset = timeseries(x_train, y_train)\n",
    "\n",
    "x_test, y_test = get_total_datas(seq_len, test_data, shuffle=True)\n",
    "test_dataset = timeseries(x_test, y_test)\n",
    "\n",
    "model = urvae.to(device)\n",
    "urvae.rnn.init_hidden(batch_size)\n",
    "criterion = VAE_Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 50\n",
    "\n",
    "for i in range(epochs):\n",
    "    ts_train_loader = DataLoader(ts_dataset, shuffle=True, batch_size=batch_size)\n",
    "    test_train_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n",
    "    model.train()\n",
    "    for j, data in enumerate(ts_train_loader):\n",
    "        if data[0].shape[0] != batch_size:\n",
    "            break\n",
    "        curr_data = data[0].clone().detach(), data[1].clone().detach()\n",
    "        output = model(curr_data[0])\n",
    "        loss = criterion(output[2], output[3], output[0], curr_data[1])\n",
    "        #make_dot(loss, params=dict(model.named_parameters())).render(f\"graph\", format=\"png\")\n",
    "        #result = model.loss_function(curr_data[1].clone(), *output, **{'M_N': 1})\n",
    "        #loss = result['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    for j, data in enumerate(test_train_loader):\n",
    "        if data[0].shape[0] != batch_size:\n",
    "            break\n",
    "        curr_data = data[0].clone().detach(), data[1].clone().detach()\n",
    "        output = model(curr_data[0])\n",
    "        val_loss = criterion(output[2], output[3], output[0], curr_data[1])\n",
    "        \n",
    "    if i % 2 == 0:\n",
    "        print(i, 'th iteration : ', val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('test2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05df2373b415eafa06c2ece122c4624d761dfbc867a44e9909e9177350fa44ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
